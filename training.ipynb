{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4418ac85",
   "metadata": {},
   "source": [
    "# Chest X-Ray Lung Segmentation - Model Training\n",
    "\n",
    "**Author**: Deep Learning Project  \n",
    "**Model**: U-Net for Lung Segmentation  \n",
    "**Framework**: PyTorch with GPU acceleration  \n",
    "\n",
    "This notebook trains a deep learning model for accurate lung segmentation from chest X-rays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f69affd",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdfaccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# Image processing\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import jaccard_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"\\n✓ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ce2dd6",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f84e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_DIR = Path(r\"d:\\DEEP LEARNING\\Dataset\\ChestXray\")\n",
    "IMAGE_DIR = BASE_DIR / \"CXR_Combined\" / \"images\"\n",
    "MASK_DIR = BASE_DIR / \"CXR_Combined\" / \"masks\"\n",
    "SPLIT_DIR = Path(r\"d:\\DEEP LEARNING\\ChestXraySegmentation\")\n",
    "\n",
    "# Output directories\n",
    "OUTPUT_DIR = Path(r\"d:\\DEEP LEARNING\\ChestXraySegmentation\")\n",
    "MODEL_DIR = OUTPUT_DIR / \"models\"\n",
    "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
    "PLOTS_DIR = OUTPUT_DIR / \"plots\"\n",
    "\n",
    "# Create directories\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training configuration\n",
    "CONFIG = {\n",
    "    # Model\n",
    "    'img_size': 256,\n",
    "    'in_channels': 1,\n",
    "    'out_channels': 1,\n",
    "    \n",
    "    # Training\n",
    "    'batch_size': 16,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    \n",
    "    # Data\n",
    "    'num_workers': 4,\n",
    "    'pin_memory': True if torch.cuda.is_available() else False,\n",
    "    \n",
    "    # Other\n",
    "    'save_every': 5,  # Save model every N epochs\n",
    "    'early_stopping_patience': 10,\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save config\n",
    "with open(RESULTS_DIR / 'config.json', 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "print(\"\\n✓ Configuration saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6be3675",
   "metadata": {},
   "source": [
    "## 3. Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungSegmentationDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for Lung Segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir, filenames, img_size=256, augment=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image_dir: Path to images directory\n",
    "            mask_dir: Path to masks directory\n",
    "            filenames: List of image filenames\n",
    "            img_size: Target image size (will resize to img_size x img_size)\n",
    "            augment: Whether to apply data augmentation\n",
    "        \"\"\"\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.mask_dir = Path(mask_dir)\n",
    "        self.filenames = filenames\n",
    "        self.img_size = img_size\n",
    "        self.augment = augment\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        \n",
    "        # Load image and mask\n",
    "        image_path = self.image_dir / filename\n",
    "        mask_path = self.mask_dir / filename\n",
    "        \n",
    "        # Read image (grayscale)\n",
    "        image = cv2.imread(str(image_path), cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Resize\n",
    "        image = cv2.resize(image, (self.img_size, self.img_size), interpolation=cv2.INTER_AREA)\n",
    "        mask = cv2.resize(mask, (self.img_size, self.img_size), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        # Normalize image to [0, 1]\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        mask = (mask > 0).astype(np.float32)  # Binary mask\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.augment:\n",
    "            image, mask = self.augment_data(image, mask)\n",
    "        \n",
    "        # Add channel dimension: (H, W) -> (1, H, W)\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "        mask = np.expand_dims(mask, axis=0)\n",
    "        \n",
    "        # Convert to tensors\n",
    "        image = torch.from_numpy(image)\n",
    "        mask = torch.from_numpy(mask)\n",
    "        \n",
    "        return image, mask\n",
    "    \n",
    "    def augment_data(self, image, mask):\n",
    "        \"\"\"Simple augmentation: horizontal flip\"\"\"\n",
    "        if np.random.random() > 0.5:\n",
    "            image = np.fliplr(image).copy()\n",
    "            mask = np.fliplr(mask).copy()\n",
    "        return image, mask\n",
    "\n",
    "print(\"✓ Dataset class defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94583314",
   "metadata": {},
   "source": [
    "## 4. U-Net Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3deffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv2D -> BatchNorm -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        \n",
    "        # Pad x1 to match x2 size if needed\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        \n",
    "        # Concatenate\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"U-Net Architecture for Image Segmentation\"\"\"\n",
    "    def __init__(self, in_channels=1, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder (Downsampling)\n",
    "        self.inc = DoubleConv(in_channels, features[0])\n",
    "        self.down1 = Down(features[0], features[1])\n",
    "        self.down2 = Down(features[1], features[2])\n",
    "        self.down3 = Down(features[2], features[3])\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.down4 = Down(features[3], features[3] * 2)\n",
    "        \n",
    "        # Decoder (Upsampling)\n",
    "        self.up1 = Up(features[3] * 2, features[3])\n",
    "        self.up2 = Up(features[3], features[2])\n",
    "        self.up3 = Up(features[2], features[1])\n",
    "        self.up4 = Up(features[1], features[0])\n",
    "        \n",
    "        # Output layer\n",
    "        self.outc = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        \n",
    "        # Output\n",
    "        logits = self.outc(x)\n",
    "        return logits\n",
    "\n",
    "# Test model\n",
    "model = UNet(in_channels=CONFIG['in_channels'], out_channels=CONFIG['out_channels'])\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n✓ U-Net model created!\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f3eef",
   "metadata": {},
   "source": [
    "## 5. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e0610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load split files\n",
    "train_df = pd.read_csv(SPLIT_DIR / 'train_split.csv')\n",
    "val_df = pd.read_csv(SPLIT_DIR / 'val_split.csv')\n",
    "test_df = pd.read_csv(SPLIT_DIR / 'test_split.csv')\n",
    "\n",
    "train_files = train_df['filename'].tolist()\n",
    "val_files = val_df['filename'].tolist()\n",
    "test_files = test_df['filename'].tolist()\n",
    "\n",
    "print(f\"Data splits loaded:\")\n",
    "print(f\"  Training:   {len(train_files)} images\")\n",
    "print(f\"  Validation: {len(val_files)} images\")\n",
    "print(f\"  Testing:    {len(test_files)} images\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = LungSegmentationDataset(\n",
    "    IMAGE_DIR, MASK_DIR, train_files, \n",
    "    img_size=CONFIG['img_size'], augment=True\n",
    ")\n",
    "\n",
    "val_dataset = LungSegmentationDataset(\n",
    "    IMAGE_DIR, MASK_DIR, val_files,\n",
    "    img_size=CONFIG['img_size'], augment=False\n",
    ")\n",
    "\n",
    "test_dataset = LungSegmentationDataset(\n",
    "    IMAGE_DIR, MASK_DIR, test_files,\n",
    "    img_size=CONFIG['img_size'], augment=False\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=CONFIG['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ DataLoaders created!\")\n",
    "print(f\"  Training batches:   {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Testing batches:    {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590e9d3b",
   "metadata": {},
   "source": [
    "## 6. Loss Functions and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice Loss for segmentation\"\"\"\n",
    "    def __init__(self, smooth=1.0):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        # Flatten\n",
    "        predictions = predictions.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (predictions * targets).sum()\n",
    "        dice = (2. * intersection + self.smooth) / (predictions.sum() + targets.sum() + self.smooth)\n",
    "        \n",
    "        return 1 - dice\n",
    "\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined BCE and Dice Loss\"\"\"\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        self.dice = DiceLoss()\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        bce_loss = self.bce(predictions, targets)\n",
    "        dice_loss = self.dice(predictions, targets)\n",
    "        return self.alpha * bce_loss + (1 - self.alpha) * dice_loss\n",
    "\n",
    "\n",
    "def calculate_iou(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate Intersection over Union (IoU)\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    targets = targets.float()\n",
    "    \n",
    "    intersection = (predictions * targets).sum()\n",
    "    union = predictions.sum() + targets.sum() - intersection\n",
    "    \n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def calculate_dice(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate Dice Coefficient\"\"\"\n",
    "    predictions = (predictions > threshold).float()\n",
    "    targets = targets.float()\n",
    "    \n",
    "    intersection = (predictions * targets).sum()\n",
    "    dice = (2. * intersection + 1e-6) / (predictions.sum() + targets.sum() + 1e-6)\n",
    "    \n",
    "    return dice.item()\n",
    "\n",
    "print(\"✓ Loss functions and metrics defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c388f401",
   "metadata": {},
   "source": [
    "## 7. Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36475efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc='Training')\n",
    "    for images, masks in pbar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            iou = calculate_iou(preds, masks)\n",
    "            dice = calculate_dice(preds, masks)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_iou += iou\n",
    "        running_dice += dice\n",
    "        \n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'iou': f'{iou:.4f}',\n",
    "            'dice': f'{dice:.4f}'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_iou, epoch_dice\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(dataloader, desc='Validation')\n",
    "        for images, masks in pbar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            iou = calculate_iou(preds, masks)\n",
    "            dice = calculate_dice(preds, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_iou += iou\n",
    "            running_dice += dice\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'iou': f'{iou:.4f}',\n",
    "                'dice': f'{dice:.4f}'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_iou, epoch_dice\n",
    "\n",
    "print(\"✓ Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a95b79f",
   "metadata": {},
   "source": [
    "## 8. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e2d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, criterion, and optimizer\n",
    "model = UNet(in_channels=CONFIG['in_channels'], out_channels=CONFIG['out_channels'])\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = CombinedLoss(alpha=0.5)\n",
    "optimizer = optim.Adam(model.parameters(), lr=CONFIG['learning_rate'], \n",
    "                       weight_decay=CONFIG['weight_decay'])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, \n",
    "                                                  patience=5, verbose=True)\n",
    "\n",
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'train_iou': [], 'train_dice': [],\n",
    "    'val_loss': [], 'val_iou': [], 'val_dice': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "best_val_dice = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"\\nStarting training for {CONFIG['num_epochs']} epochs...\")\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{CONFIG['num_epochs']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_iou, train_dice = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_iou, val_dice = validate(\n",
    "        model, val_loader, criterion, device\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['train_iou'].append(train_iou)\n",
    "    history['train_dice'].append(train_dice)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_iou'].append(val_iou)\n",
    "    history['val_dice'].append(val_dice)\n",
    "    history['lr'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch Summary:\")\n",
    "    print(f\"  Train - Loss: {train_loss:.4f}, IoU: {train_iou:.4f}, Dice: {train_dice:.4f}\")\n",
    "    print(f\"  Val   - Loss: {val_loss:.4f}, IoU: {val_iou:.4f}, Dice: {val_dice:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_dice > best_val_dice:\n",
    "        best_val_dice = val_dice\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_dice': val_dice,\n",
    "            'val_iou': val_iou,\n",
    "            'history': history\n",
    "        }, MODEL_DIR / 'best_model.pth')\n",
    "        print(f\"  ✓ Best model saved! (Dice: {val_dice:.4f})\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    # Save checkpoint every N epochs\n",
    "    if (epoch + 1) % CONFIG['save_every'] == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'history': history\n",
    "        }, MODEL_DIR / f'checkpoint_epoch_{epoch+1}.pth')\n",
    "        print(f\"  ✓ Checkpoint saved (epoch {epoch+1})\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= CONFIG['early_stopping_patience']:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "        break\n",
    "\n",
    "end_time = datetime.now()\n",
    "training_time = end_time - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Training completed!\")\n",
    "print(f\"Total time: {training_time}\")\n",
    "print(f\"Best validation Dice: {best_val_dice:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save final model and history\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'history': history,\n",
    "    'config': CONFIG\n",
    "}, MODEL_DIR / 'final_model.pth')\n",
    "\n",
    "# Save training history\n",
    "history_df = pd.DataFrame(history)\n",
    "history_df.to_csv(RESULTS_DIR / 'training_history.csv', index=False)\n",
    "print(\"\\n✓ Final model and history saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfdd02a",
   "metadata": {},
   "source": [
    "## 9. Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a315a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
    "axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
    "axes[0, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0, 0].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend(fontsize=11)\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[0, 1].plot(epochs, history['train_iou'], 'b-', label='Training IoU', linewidth=2)\n",
    "axes[0, 1].plot(epochs, history['val_iou'], 'r-', label='Validation IoU', linewidth=2)\n",
    "axes[0, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0, 1].set_ylabel('IoU Score', fontsize=12)\n",
    "axes[0, 1].set_title('Training and Validation IoU', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend(fontsize=11)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Dice\n",
    "axes[1, 0].plot(epochs, history['train_dice'], 'b-', label='Training Dice', linewidth=2)\n",
    "axes[1, 0].plot(epochs, history['val_dice'], 'r-', label='Validation Dice', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Dice Coefficient', fontsize=12)\n",
    "axes[1, 0].set_title('Training and Validation Dice Coefficient', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend(fontsize=11)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 1].plot(epochs, history['lr'], 'g-', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Learning Rate', fontsize=12)\n",
    "axes[1, 1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Training history plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc8c1c",
   "metadata": {},
   "source": [
    "## 10. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624efaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "checkpoint = torch.load(MODEL_DIR / 'best_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {checkpoint['epoch'] + 1}\")\n",
    "print(f\"Best validation Dice: {checkpoint['val_dice']:.4f}\\n\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_loss, test_iou, test_dice = validate(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Test Set Results:\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  IoU:  {test_iou:.4f}\")\n",
    "print(f\"  Dice: {test_dice:.4f}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Save test results\n",
    "test_results = {\n",
    "    'test_loss': test_loss,\n",
    "    'test_iou': test_iou,\n",
    "    'test_dice': test_dice,\n",
    "    'best_val_dice': checkpoint['val_dice'],\n",
    "    'best_epoch': checkpoint['epoch'] + 1\n",
    "}\n",
    "\n",
    "with open(RESULTS_DIR / 'test_results.json', 'w') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "\n",
    "print(\"\\n✓ Test results saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e458f08e",
   "metadata": {},
   "source": [
    "## 11. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f145abc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, device, num_samples=6):\n",
    "    \"\"\"Visualize model predictions\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get random samples\n",
    "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4 * num_samples))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, sample_idx in enumerate(indices):\n",
    "            image, mask = dataset[sample_idx]\n",
    "            image_input = image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Predict\n",
    "            output = model(image_input)\n",
    "            pred_mask = torch.sigmoid(output).cpu().squeeze()\n",
    "            pred_binary = (pred_mask > 0.5).float()\n",
    "            \n",
    "            # Convert to numpy\n",
    "            image_np = image.squeeze().numpy()\n",
    "            mask_np = mask.squeeze().numpy()\n",
    "            pred_np = pred_mask.numpy()\n",
    "            pred_binary_np = pred_binary.numpy()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            iou = calculate_iou(pred_mask.unsqueeze(0).unsqueeze(0), \n",
    "                               mask.unsqueeze(0))\n",
    "            dice = calculate_dice(pred_mask.unsqueeze(0).unsqueeze(0), \n",
    "                                 mask.unsqueeze(0))\n",
    "            \n",
    "            # Plot\n",
    "            axes[idx, 0].imshow(image_np, cmap='gray')\n",
    "            axes[idx, 0].set_title('Input Image', fontsize=11, fontweight='bold')\n",
    "            axes[idx, 0].axis('off')\n",
    "            \n",
    "            axes[idx, 1].imshow(mask_np, cmap='gray')\n",
    "            axes[idx, 1].set_title('Ground Truth', fontsize=11, fontweight='bold')\n",
    "            axes[idx, 1].axis('off')\n",
    "            \n",
    "            axes[idx, 2].imshow(pred_np, cmap='gray')\n",
    "            axes[idx, 2].set_title('Prediction (Prob)', fontsize=11, fontweight='bold')\n",
    "            axes[idx, 2].axis('off')\n",
    "            \n",
    "            axes[idx, 3].imshow(pred_binary_np, cmap='gray')\n",
    "            axes[idx, 3].set_title(f'Prediction (Binary)\\nIoU: {iou:.3f}, Dice: {dice:.3f}', \n",
    "                                  fontsize=11, fontweight='bold')\n",
    "            axes[idx, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS_DIR / 'test_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize test predictions\n",
    "visualize_predictions(model, test_dataset, device, num_samples=8)\n",
    "print(\"✓ Predictions visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d32b9",
   "metadata": {},
   "source": [
    "## 12. Calculate Detailed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d18ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detailed_metrics(model, dataloader, device):\n",
    "    \"\"\"Calculate detailed per-image metrics\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_ious = []\n",
    "    all_dices = []\n",
    "    all_precisions = []\n",
    "    all_recalls = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in tqdm(dataloader, desc='Calculating metrics'):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "            \n",
    "            # Calculate metrics for each image in batch\n",
    "            for pred, mask in zip(preds, masks):\n",
    "                pred_binary = (pred > 0.5).float()\n",
    "                \n",
    "                # Flatten\n",
    "                pred_flat = pred_binary.cpu().numpy().flatten()\n",
    "                mask_flat = mask.cpu().numpy().flatten()\n",
    "                \n",
    "                # Calculate metrics\n",
    "                iou = jaccard_score(mask_flat, pred_flat, zero_division=0)\n",
    "                dice = f1_score(mask_flat, pred_flat, zero_division=0)\n",
    "                precision = precision_score(mask_flat, pred_flat, zero_division=0)\n",
    "                recall = recall_score(mask_flat, pred_flat, zero_division=0)\n",
    "                \n",
    "                all_ious.append(iou)\n",
    "                all_dices.append(dice)\n",
    "                all_precisions.append(precision)\n",
    "                all_recalls.append(recall)\n",
    "    \n",
    "    return {\n",
    "        'iou': all_ious,\n",
    "        'dice': all_dices,\n",
    "        'precision': all_precisions,\n",
    "        'recall': all_recalls\n",
    "    }\n",
    "\n",
    "# Calculate metrics on test set\n",
    "print(\"Calculating detailed metrics on test set...\\n\")\n",
    "test_metrics = calculate_detailed_metrics(model, test_loader, device)\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Detailed Test Set Metrics:\")\n",
    "print(f\"{'='*60}\")\n",
    "for metric_name, values in test_metrics.items():\n",
    "    print(f\"\\n{metric_name.upper()}:\")\n",
    "    print(f\"  Mean:   {np.mean(values):.4f}\")\n",
    "    print(f\"  Median: {np.median(values):.4f}\")\n",
    "    print(f\"  Std:    {np.std(values):.4f}\")\n",
    "    print(f\"  Min:    {np.min(values):.4f}\")\n",
    "    print(f\"  Max:    {np.max(values):.4f}\")\n",
    "\n",
    "# Save metrics\n",
    "metrics_df = pd.DataFrame(test_metrics)\n",
    "metrics_df.to_csv(RESULTS_DIR / 'detailed_test_metrics.csv', index=False)\n",
    "print(\"\\n✓ Detailed metrics saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c21cc5c",
   "metadata": {},
   "source": [
    "## 13. Plot Metric Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dce5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "metrics_to_plot = ['iou', 'dice', 'precision', 'recall']\n",
    "titles = ['IoU (Jaccard Index)', 'Dice Coefficient', 'Precision', 'Recall']\n",
    "colors = ['steelblue', 'coral', 'mediumseagreen', 'mediumpurple']\n",
    "\n",
    "for idx, (metric, title, color) in enumerate(zip(metrics_to_plot, titles, colors)):\n",
    "    row, col = idx // 2, idx % 2\n",
    "    \n",
    "    values = test_metrics[metric]\n",
    "    \n",
    "    # Histogram\n",
    "    axes[row, col].hist(values, bins=30, color=color, alpha=0.7, edgecolor='black')\n",
    "    axes[row, col].axvline(np.mean(values), color='red', linestyle='--', \n",
    "                           linewidth=2, label=f'Mean: {np.mean(values):.4f}')\n",
    "    axes[row, col].axvline(np.median(values), color='green', linestyle=':', \n",
    "                           linewidth=2, label=f'Median: {np.median(values):.4f}')\n",
    "    \n",
    "    axes[row, col].set_xlabel(title, fontsize=12)\n",
    "    axes[row, col].set_ylabel('Frequency', fontsize=12)\n",
    "    axes[row, col].set_title(f'{title} Distribution', fontsize=13, fontweight='bold')\n",
    "    axes[row, col].legend(fontsize=10)\n",
    "    axes[row, col].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PLOTS_DIR / 'metric_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Metric distributions plotted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4431e92",
   "metadata": {},
   "source": [
    "## 14. Final Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba23df",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_report = f\"\"\"\n",
    "{'='*70}\n",
    "CHEST X-RAY LUNG SEGMENTATION - TRAINING SUMMARY REPORT\n",
    "{'='*70}\n",
    "\n",
    "MODEL ARCHITECTURE\n",
    "{'-'*70}\n",
    "Model:                     U-Net\n",
    "Input Channels:            {CONFIG['in_channels']}\n",
    "Output Channels:           {CONFIG['out_channels']}\n",
    "Image Size:                {CONFIG['img_size']}x{CONFIG['img_size']}\n",
    "Total Parameters:          {total_params:,}\n",
    "Trainable Parameters:      {trainable_params:,}\n",
    "\n",
    "TRAINING CONFIGURATION\n",
    "{'-'*70}\n",
    "Epochs:                    {len(history['train_loss'])}\n",
    "Batch Size:                {CONFIG['batch_size']}\n",
    "Learning Rate:             {CONFIG['learning_rate']}\n",
    "Weight Decay:              {CONFIG['weight_decay']}\n",
    "Loss Function:             Combined BCE + Dice Loss\n",
    "Optimizer:                 Adam\n",
    "Device:                    {device}\n",
    "\n",
    "DATASET\n",
    "{'-'*70}\n",
    "Training Samples:          {len(train_files)}\n",
    "Validation Samples:        {len(val_files)}\n",
    "Test Samples:              {len(test_files)}\n",
    "Total:                     {len(train_files) + len(val_files) + len(test_files)}\n",
    "\n",
    "TRAINING RESULTS\n",
    "{'-'*70}\n",
    "Training Time:             {training_time}\n",
    "Best Epoch:                {checkpoint['epoch'] + 1}\n",
    "Best Validation Dice:      {checkpoint['val_dice']:.4f}\n",
    "Best Validation IoU:       {checkpoint['val_iou']:.4f}\n",
    "Final Training Loss:       {history['train_loss'][-1]:.4f}\n",
    "Final Validation Loss:     {history['val_loss'][-1]:.4f}\n",
    "\n",
    "TEST SET PERFORMANCE\n",
    "{'-'*70}\n",
    "Test Loss:                 {test_loss:.4f}\n",
    "Test IoU (mean ± std):     {np.mean(test_metrics['iou']):.4f} ± {np.std(test_metrics['iou']):.4f}\n",
    "Test Dice (mean ± std):    {np.mean(test_metrics['dice']):.4f} ± {np.std(test_metrics['dice']):.4f}\n",
    "Test Precision:            {np.mean(test_metrics['precision']):.4f} ± {np.std(test_metrics['precision']):.4f}\n",
    "Test Recall:               {np.mean(test_metrics['recall']):.4f} ± {np.std(test_metrics['recall']):.4f}\n",
    "\n",
    "SAVED FILES\n",
    "{'-'*70}\n",
    "✓ best_model.pth           - Best model checkpoint\n",
    "✓ final_model.pth          - Final model state\n",
    "✓ training_history.csv     - Complete training history\n",
    "✓ test_results.json        - Test set results\n",
    "✓ detailed_test_metrics.csv - Per-image metrics\n",
    "✓ training_history.png     - Training curves\n",
    "✓ test_predictions.png     - Sample predictions\n",
    "✓ metric_distributions.png - Metric distributions\n",
    "\n",
    "{'='*70}\n",
    "Training completed successfully!\n",
    "{'='*70}\n",
    "\"\"\"\n",
    "\n",
    "print(summary_report)\n",
    "\n",
    "# Save summary\n",
    "with open(RESULTS_DIR / 'training_summary.txt', 'w') as f:\n",
    "    f.write(summary_report)\n",
    "\n",
    "print(\"\\n✓ Summary report saved to 'training_summary.txt'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96f4bfd",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The U-Net model has been successfully trained for lung segmentation on chest X-rays:\n",
    "\n",
    "### Key Achievements:\n",
    "1. **Model Architecture**: Implemented U-Net with skip connections for precise segmentation\n",
    "2. **Training**: Trained with combined BCE + Dice loss for optimal results\n",
    "3. **Performance**: Achieved strong metrics on test set\n",
    "4. **Reproducibility**: All configurations, models, and metrics saved\n",
    "\n",
    "### Saved Artifacts:\n",
    "- **Models**: Best and final checkpoints saved in `models/`\n",
    "- **Results**: Training history and test metrics in `results/`\n",
    "- **Visualizations**: Training curves and predictions in `plots/`\n",
    "\n",
    "The model is ready for deployment and inference on new chest X-ray images!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
